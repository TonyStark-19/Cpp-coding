# Big-O Notation

## ğŸ“Œ Introduction

**Big-O Notation** is a mathematical way to describe the **time and space complexity** of an algorithm as the input size grows.

It helps us understand **how an algorithm scales**, not how fast it runs on a specific machine.

In simple terms:

> Big-O tells us **how an algorithm behaves for large inputs**.

---

## ğŸ¤” Why Do We Need Big-O?

* Machines differ in speed
* Programming languages differ in performance
* Input size can grow very large

Big-O focuses on the **growth rate**, ignoring constants and minor details.

---

## ğŸ“ˆ How Big-O Works

Big-O expresses complexity using:

* Input size â†’ `n`
* Upper bound of growth â†’ worst-case scenario

We usually care about the **worst-case performance**, because it guarantees limits.

---

## ğŸ”¢ Common Big-O Notations

### ğŸŸ¢ O(1) â€” Constant Time

* Execution time does not depend on input size
* Example: accessing an array element by index

---

### ğŸ”µ O(n) â€” Linear Time

* Time grows directly with input size
* Example: looping through an array once

---

### ğŸŸ¡ O(nÂ²) â€” Quadratic Time

* Nested loops over the same input
* Example: comparing every pair of elements

---

### ğŸŸ  O(log n) â€” Logarithmic Time

* Input size reduces at every step
* Example: Binary Search

---

### ğŸ”´ O(n log n) â€” Linearithmic Time

* Combination of linear and logarithmic
* Example: Merge Sort, Quick Sort (average case)

---

### âš« O(2â¿) â€” Exponential Time

* Growth doubles with each input increase
* Example: recursive solutions without optimization

---

## ğŸš« What Big-O Ignores

Big-O notation ignores:

* Constant factors (O(2n) â†’ O(n))
* Lower-order terms (O(nÂ² + n) â†’ O(nÂ²))
* Hardware and language differences

This keeps analysis simple and universal.

---

## âš–ï¸ Best, Average & Worst Case

* **Best Case**: Minimum time taken
* **Average Case**: Expected time
* **Worst Case**: Maximum time taken

Big-O usually represents the **worst case**.

---

## ğŸ§  Example Simplification

```
for (i = 0; i < n; i++) {
  for (j = 0; j < n; j++) {
    // constant operation
  }
}
```

* Inner loop runs `n` times
* Outer loop runs `n` times
* Total operations â†’ `n * n`

ğŸ‘‰ **Time Complexity: O(nÂ²)**

---

## ğŸ¯ Key Takeaways

* Big-O measures algorithm scalability
* Focuses on worst-case performance
* Ignores constants and small details
* Helps compare and choose efficient algorithms

---

> Big-O is not about writing faster code today, but about writing code that scales tomorrow.
=